{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, accuracy_score, classification_report, cohen_kappa_score\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "from skimage.segmentation import slic, mark_boundaries, felzenszwalb, quickshift, random_walker\n",
    "from scipy.sparse import coo_matrix\n",
    "from torchinfo import summary\n",
    "from operator import index, truediv\n",
    "import matplotlib.pyplot as plt\n",
    "import spectral\n",
    "\n",
    "# CUDA or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "####################################################################\n",
    "\n",
    "class CNN_Denoise_layer(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        super(CNN_Denoise_layer, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.BN = nn.BatchNorm2d(in_dim)\n",
    "        self.OO_conv = nn.Conv2d(in_dim, out_dim, kernel_size=(1, 1))\n",
    "        self.Activition = nn.LeakyReLU()\n",
    "    def forward(self, X):\n",
    "        X = self.BN(X)\n",
    "        X = self.OO_conv(X)\n",
    "        X = self.Activition(X)\n",
    "        return X\n",
    "\n",
    "class SSConv(nn.Module):\n",
    "    '''\n",
    "    Spectral-Spatial Convolution\n",
    "    '''\n",
    "    def __init__(self, in_ch, out_ch,kernel_size=3):\n",
    "        super(SSConv, self).__init__()\n",
    "        self.point_conv = nn.Conv2d(\n",
    "            in_channels=in_ch,\n",
    "            out_channels=out_ch,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            groups=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.depth_conv = nn.Conv2d(\n",
    "            in_channels=out_ch,\n",
    "            out_channels=out_ch,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=kernel_size//2,\n",
    "            groups=out_ch\n",
    "        )\n",
    "        \n",
    "        self.Act1 = nn.LeakyReLU()\n",
    "        self.Act2 = nn.LeakyReLU()\n",
    "        self.BN=nn.BatchNorm2d(in_ch)\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.point_conv(self.BN(input))\n",
    "        out = self.Act1(out)\n",
    "        out = self.depth_conv(out)\n",
    "        out = self.Act2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# adaptive improved GCN\n",
    "class AIGCN_layer(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, \n",
    "                 A: torch.Tensor, AIGCN_K: int):\n",
    "        # in_dim: dim of input feature in current layer\n",
    "        # out_dim: dim of output feature in current layer\n",
    "        super(AIGCN_layer, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.AIGCN_K = AIGCN_K\n",
    "        self.A = A\n",
    "        n_nodes = self.A.shape[0]\n",
    "        self.I = torch.eye(n_nodes, n_nodes, requires_grad=False).to(device)\n",
    "\n",
    "        self.BN = nn.BatchNorm1d(in_dim)\n",
    "        self.GCN_liner = nn.Linear(in_dim, out_dim)\n",
    "        self.Activition = nn.LeakyReLU()\n",
    "        \n",
    "        self.h_coeffs = torch.nn.Parameter(torch.tensor([0.01],requires_grad=True))\n",
    "\n",
    "\n",
    "    def A_to_D_inv(self, A: torch.Tensor):\n",
    "        d = A.sum(1)\n",
    "        d = 1/torch.sqrt(d)\n",
    "        D_inv = torch.diag(d)\n",
    "        return D_inv        \n",
    "    def get_normal_Adjacency(self, A: torch.Tensor):\n",
    "        d = A.sum(1)\n",
    "        d = 1/torch.sqrt(d)\n",
    "        D_inv = torch.diag(d)\n",
    "        A = torch.matmul(D_inv, torch.matmul(A,D_inv))\n",
    "        return A\n",
    "    def get_randwalk_Adjacency(self, A: torch.Tensor):\n",
    "        d = A.sum(1)\n",
    "        d = 1/d\n",
    "        D_inv = torch.diag(d)\n",
    "        A = torch.matmul(D_inv, A)\n",
    "        return A    \n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.BN(X)\n",
    "\n",
    "     ## method-1 good normal A ===========================\n",
    "        A = self.I + torch.abs(self.h_coeffs)*self.A\n",
    "        A = self.get_normal_Adjacency(A)\n",
    "        A = torch.matrix_power(A, self.AIGCN_K)\n",
    "        X = torch.mm(A, self.GCN_liner(X))\n",
    "\n",
    "        X = self.Activition(X)          \n",
    "\n",
    "        return X\n",
    "        \n",
    "\n",
    "# adaptive improved GCN with multiple affinity matrics\n",
    "class AIGCN_MA_layer(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, \n",
    "            A1: torch.Tensor, A2: torch, AIGCN_K: int):\n",
    "        super(AIGCN_MA_layer, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.AIGCN_K = AIGCN_K\n",
    "        self.A1 = A1\n",
    "        self.A2 = A2\n",
    "        n_nodes = self.A1.shape[0]\n",
    "        self.I = torch.eye(n_nodes, n_nodes, requires_grad=False).to(device)\n",
    "\n",
    "        self.BN = nn.BatchNorm1d(in_dim)\n",
    "        self.GCN_liner = nn.Linear(in_dim, out_dim)\n",
    "        self.Activition = nn.LeakyReLU()\n",
    "\n",
    "        self.alpha = torch.nn.Parameter(torch.tensor([0.5],requires_grad=True))        \n",
    "        self.h_coeffs = torch.nn.Parameter(torch.tensor([0.01],requires_grad=True))    \n",
    "        \n",
    "           \n",
    "            \n",
    "    def A_to_D_inv(self, A: torch.Tensor):\n",
    "        d = A.sum(1)\n",
    "        d = 1/torch.sqrt(d)\n",
    "        D_inv = torch.diag(d)\n",
    "        return D_inv\n",
    "    def get_randwalk_Adjacency(self, A: torch.Tensor):\n",
    "        d = A.sum(1)\n",
    "        d = 1/d\n",
    "        D_inv = torch.diag(d)\n",
    "        A = torch.matmul(D_inv, A)\n",
    "        return A        \n",
    "    def get_normal_Adjacency(self, A: torch.Tensor):\n",
    "        d = A.sum(1)\n",
    "        d = 1/torch.sqrt(d)\n",
    "        D_inv = torch.diag(d)\n",
    "        A = torch.matmul(D_inv, torch.matmul(A,D_inv))\n",
    "        return A    \n",
    "    def forward(self, X):\n",
    "        X = self.BN(X)\n",
    "\n",
    "        # # method-1 \n",
    "        A0 = (1-torch.abs(self.alpha))*self.A1 + torch.abs(self.alpha)*self.A2\n",
    "        A = self.I + torch.abs(self.h_coeffs)*A0\n",
    "        A = self.get_normal_Adjacency(A)\n",
    "        A = torch.matrix_power(A, self.AIGCN_K)\n",
    "        X = torch.mm(A, self.GCN_liner(X))\n",
    "        X = self.Activition(X)              \n",
    "        \n",
    "        # # method-2 random walk\n",
    "        # A0 = (1-torch.abs(self.alpha))*self.A1 + torch.abs(self.alpha)*self.A2\n",
    "        # A = self.I + torch.abs(self.h_coeffs)*A0\n",
    "        # A = self.get_randwalk_Adjacency(A)\n",
    "        # A = torch.matrix_power(A, self.AIGCN_K)\n",
    "        # X = torch.mm(A, self.GCN_liner(X))\n",
    "        # X = self.Activition(X)               \n",
    "                         \n",
    "             \n",
    "        \n",
    "        return X        \n",
    "    \n",
    "class AIGCN_NET(nn.Module):\n",
    "    def __init__(self, height: int, width: int, in_dim: int, class_num: int,\n",
    "                 H: torch.Tensor, Pos0:torch, \n",
    "                 As: torch.Tensor, Af:torch.Tensor, \n",
    "                 AIGCN_K_As: int,AIGCN_K_Af: int,AIGCN_K_Ac: int):\n",
    "        super(AIGCN_NET, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.in_dim = in_dim\n",
    "        self.class_num = class_num\n",
    "        self.H = H\n",
    "        self.Pos0 = Pos0\n",
    "        self.As = As\n",
    "        self.Af = Af\n",
    "        self.n_nodes = As.shape[0]\n",
    "        self.AIGCN_K_As = AIGCN_K_As\n",
    "        self.AIGCN_K_Af = AIGCN_K_Af\n",
    "        self.AIGCN_K_Ac = AIGCN_K_Ac\n",
    "\n",
    "        out_dim     = 128\n",
    "        final_dim   = 128\n",
    "        # (1) CNN denoise layer\n",
    "        self.CNN_denoise_branch = nn.Sequential()\n",
    "        self.CNN_denoise_branch.add_module('CNNDenoise1',\n",
    "                CNN_Denoise_layer(in_dim, out_dim))\n",
    "        self.CNN_denoise_branch.add_module('CNNDenoise2',\n",
    "                CNN_Denoise_layer(out_dim, out_dim))\n",
    "        \n",
    "        ## good\n",
    "        # (2) As\n",
    "        self.As_layer1 = AIGCN_layer(out_dim, out_dim, As, AIGCN_K_As)\n",
    "        self.As_layer2 = AIGCN_layer(out_dim, final_dim, As, AIGCN_K_As)\n",
    "        \n",
    "        # (3) Af\n",
    "        self.Af_layer1 = AIGCN_layer(out_dim, out_dim, Af, AIGCN_K_Af)\n",
    "        self.Af_layer2 = AIGCN_layer(out_dim, final_dim, Af, AIGCN_K_Af)\n",
    "        \n",
    "        \n",
    "        # (4) As+Af\n",
    "        self.Ac_layer1 = AIGCN_MA_layer(out_dim, out_dim, As, Af, AIGCN_K_Ac)\n",
    "        self.Ac_layer2 = AIGCN_MA_layer(out_dim, final_dim, As, Af, AIGCN_K_Ac)\n",
    "     \n",
    "        \n",
    "        # (5) CNN: SSConv \n",
    "        self.CNN_Branch = nn.Sequential()\n",
    "        self.CNN_Branch.add_module('CNN_Branch1',\n",
    "                                SSConv(out_dim, out_dim,kernel_size=5))\n",
    "        self.CNN_Branch.add_module('CNN_Branch2',\n",
    "                                SSConv(out_dim, final_dim,kernel_size=5))\n",
    "        \n",
    "        # (6)\n",
    "        self.Softmax_linear =nn.Sequential(nn.Linear(final_dim*3, class_num))\n",
    "\n",
    "    def pixel_2_superpixel(self, X: torch.Tensor):\n",
    "        dv = self.H.sum(0)\n",
    "        Dv_inv = torch.diag(1/dv)\n",
    "        HD = torch.mm(self.H, Dv_inv)\n",
    "        # X_flatten = X.reshape([self.height*self.width],-1)\n",
    "\n",
    "        X_flatten = X.reshape(-1, X.shape[2])\n",
    "        S = torch.mm(HD.t(), X_flatten)\n",
    "        \n",
    "        return S\n",
    "    def superpixel_2_pixel(self, S: torch.Tensor):\n",
    "        # dv = self.H.sum(0)\n",
    "        # Dv = torch.diag(1/dv)\n",
    "        # HD = torch.mm(self.H, Dv)\n",
    "\n",
    "        X = torch.matmul(self.H, S)        \n",
    "        # X = torch.matmul(HD, S)        \n",
    "        \n",
    "        return X\n",
    "\n",
    "    def forward(self, X:torch.Tensor):\n",
    "        X = self.CNN_denoise_branch(torch.unsqueeze(X.permute([2, 0, 1]), 0))\n",
    "        X = torch.squeeze(X, 0).permute([1, 2, 0])\n",
    "        X_clean = X\n",
    "              \n",
    "        # (batch_size, channel, high, weight)\n",
    "        X_clean = torch.unsqueeze(X_clean.permute([2, 0, 1]), 0)\n",
    "        Z_CNN = self.CNN_Branch(X_clean)\n",
    "        Z_CNN = torch.squeeze(Z_CNN, 0).permute([1, 2, 0]).reshape([self.height * self.width, -1])             \n",
    "        \n",
    "        # obtain superpixels S and background pixels X0\n",
    "        S = self.pixel_2_superpixel(X)\n",
    "\n",
    "        # As_GCNs \n",
    "        ZS = self.As_layer1(S)\n",
    "        ZS = self.As_layer2(ZS)\n",
    "        \n",
    "        # Af_GCNs \n",
    "        ZF = self.Af_layer1(S)\n",
    "        ZF = self.Af_layer2(ZF)\n",
    "        \n",
    "        # Ac_GCNs \n",
    "        # ZC = self.Ac_layer1(S)\n",
    "        # ZC = self.Ac_layer2(ZC)\n",
    "        \n",
    "        \n",
    "        # X_ZS = torch.matmul(self.H, ZS)\n",
    "        # X_ZF = torch.matmul(self.H, ZF)     \n",
    "        # X_ZC = torch.matmul(self.H, ZC)     \n",
    "        \n",
    "        X_ZS = self.superpixel_2_pixel(ZS)\n",
    "        X_ZF = self.superpixel_2_pixel(ZF)\n",
    "        # X_ZC = self.superpixel_2_pixel(ZC)\n",
    "        \n",
    "        # X_GCN = torch.concat((X_ZS, X_ZF, X_ZC), dim=1)\n",
    "        X_GCN = torch.concat((X_ZS, X_ZF), dim=1)\n",
    "        X_Z = torch.concat((X_GCN, Z_CNN), dim=1)\n",
    "        # X_Z = Z_CNN\n",
    "        Z = self.Softmax_linear(X_Z)\n",
    "  \n",
    "       \n",
    "\n",
    "        return Z\n",
    "\n",
    "def compute_loss(predict: torch.Tensor, reallabel_onehot: torch.Tensor, reallabel_mask: torch.Tensor):\n",
    "    real_labels = reallabel_onehot\n",
    "    we = -torch.mul(real_labels,torch.log(predict))\n",
    "    we = torch.mul(we, reallabel_mask)\n",
    "    pool_cross_entropy = torch.sum(we)\n",
    "    return pool_cross_entropy\n",
    "    \n",
    "\n",
    "\n",
    "def get_TrainValTest_Sets(seed: int, gt: np.array, class_count: int, train_ratio, \n",
    "                   val_ratio, samples_type: str = 'ratio', ):\n",
    "    # step2:随机10%数据作为训练样本。方式：给出训练数据与测试数据的GT\n",
    "    random.seed(seed)\n",
    "    [height, width] = gt.shape\n",
    "    gt_reshape = np.reshape(gt, [-1])\n",
    "    train_rand_idx = []\n",
    "    val_rand_idx = []\n",
    "    if samples_type == 'ratio':\n",
    "        train_number_per_class = []\n",
    "        for i in range(class_count):\n",
    "            idx = np.where(gt_reshape == i + 1)[-1]\n",
    "            samplesCount = len(idx)\n",
    "            rand_list = [i for i in range(samplesCount)]  # 用于随机的列表\n",
    "            \n",
    "            rand_idx = random.sample(rand_list,\n",
    "                                     np.ceil(samplesCount * train_ratio).astype('int32') + \\\n",
    "                                     np.ceil(samplesCount * val_ratio).astype('int32'))  # 随机数数量 四舍五入(改为上取整)\n",
    "            train_number_per_class.append(np.ceil(samplesCount * train_ratio).astype('int32'))\n",
    "            rand_real_idx_per_class = idx[rand_idx]\n",
    "            train_rand_idx.append(rand_real_idx_per_class)\n",
    "        train_rand_idx = np.array(train_rand_idx, dtype=object)\n",
    "        train_data_index = []\n",
    "        val_data_index = []\n",
    "        for c in range(train_rand_idx.shape[0]):\n",
    "            a = list(train_rand_idx[c])\n",
    "            train_data_index = train_data_index + a[:train_number_per_class[c]]\n",
    "            val_data_index = val_data_index + a[train_number_per_class[c]:]\n",
    "            # for j in range(a.shape[0]):\n",
    "            #     train_data_index.append(a[j][0:train_number_per_class])\n",
    "            #     val_data_index.append()\n",
    "        # train_data_index = np.array(train_data_index).reshape([-1])\n",
    "        # val_data_index = np.array(val_data_index).reshape([-1])\n",
    "        \n",
    "        ##将测试集（所有样本，包括训练样本）也转化为特定形式\n",
    "        train_data_index = set(train_data_index)\n",
    "        val_data_index = set(val_data_index)\n",
    "        all_data_index = [i for i in range(len(gt_reshape))]\n",
    "        all_data_index = set(all_data_index)\n",
    "        \n",
    "        # 背景像元的标签\n",
    "        background_idx = np.where(gt_reshape == 0)[-1]\n",
    "        background_idx = set(background_idx)\n",
    "        test_data_index = all_data_index - train_data_index - val_data_index - background_idx\n",
    "        \n",
    "        # # 从测试集中随机选取部分样本作为验证集\n",
    "        # val_data_count = np.ceil(val_ratio * (len(test_data_index) + len(train_data_index))).astype('int32')  # 验证集数量\n",
    "        # val_data_index = random.sample(test_data_index, val_data_count)\n",
    "        # val_data_index = set(val_data_index)\n",
    "        \n",
    "        # test_data_index = test_data_index - val_data_index  # 由于验证集为从测试集分裂出，所以测试集应减去验证集\n",
    "        \n",
    "        # 将训练集 验证集 测试集 整理\n",
    "        test_data_index = list(test_data_index)\n",
    "        train_data_index = list(train_data_index)\n",
    "        val_data_index = list(val_data_index)\n",
    "    \n",
    "    if samples_type == 'same_num':\n",
    "        if int(train_ratio) == 0 or int(val_ratio) == 0:\n",
    "            print(\"ERROR: The number of samples for train. or val. is equal to 0.\")\n",
    "            exit(-1)\n",
    "        for i in range(class_count):\n",
    "            idx = np.where(gt_reshape == i + 1)[-1]\n",
    "            samplesCount = len(idx)\n",
    "            real_train_samples_per_class = int(train_ratio)  # 每类相同数量样本,则训练比例为每类样本数量\n",
    "            real_val_samples_per_class = int(val_ratio)  # 每类相同数量样本,则训练比例为每类样本数量\n",
    "            \n",
    "            rand_list = [i for i in range(samplesCount)]  # 用于随机的列表\n",
    "            if real_train_samples_per_class >= samplesCount:\n",
    "                real_train_samples_per_class = samplesCount - 1\n",
    "                real_val_samples_per_class = 1\n",
    "            else:\n",
    "                real_val_samples_per_class = real_val_samples_per_class if (\n",
    "                                                                                       real_val_samples_per_class + real_train_samples_per_class) <= samplesCount else samplesCount - real_train_samples_per_class\n",
    "            rand_idx = random.sample(rand_list,\n",
    "                                     real_train_samples_per_class + real_val_samples_per_class)  # 随机数数量 四舍五入(改为上取整)\n",
    "            rand_real_idx_per_class_train = idx[rand_idx[0:real_train_samples_per_class]]\n",
    "            train_rand_idx.append(rand_real_idx_per_class_train)\n",
    "            if real_val_samples_per_class > 0:\n",
    "                rand_real_idx_per_class_val = idx[rand_idx[-real_val_samples_per_class:]]\n",
    "                val_rand_idx.append(rand_real_idx_per_class_val)\n",
    "        \n",
    "        train_rand_idx = np.array(train_rand_idx)\n",
    "        val_rand_idx = np.array(val_rand_idx)\n",
    "        train_data_index = []\n",
    "        for c in range(train_rand_idx.shape[0]):\n",
    "            a = train_rand_idx[c]\n",
    "            for j in range(a.shape[0]):\n",
    "                train_data_index.append(a[j])\n",
    "        train_data_index = np.array(train_data_index)\n",
    "        \n",
    "        val_data_index = []\n",
    "        for c in range(val_rand_idx.shape[0]):\n",
    "            a = val_rand_idx[c]\n",
    "            for j in range(a.shape[0]):\n",
    "                val_data_index.append(a[j])\n",
    "        val_data_index = np.array(val_data_index)\n",
    "        \n",
    "        train_data_index = set(train_data_index)\n",
    "        val_data_index = set(val_data_index)\n",
    "        \n",
    "        all_data_index = [i for i in range(len(gt_reshape))]\n",
    "        all_data_index = set(all_data_index)\n",
    "        \n",
    "        # 背景像元的标签\n",
    "        background_idx = np.where(gt_reshape == 0)[-1]\n",
    "        background_idx = set(background_idx)\n",
    "        test_data_index = all_data_index - train_data_index - val_data_index - background_idx\n",
    "        \n",
    "        # # 从测试集中随机选取部分样本作为验证集\n",
    "        # val_data_count = int(val_samples)  # 验证集数量\n",
    "        # val_data_index = random.sample(test_data_index, val_data_count)\n",
    "        # val_data_index = set(val_data_index)\n",
    "        \n",
    "        # test_data_index = test_data_index - val_data_index\n",
    "        # 将训练集 验证集 测试集 整理\n",
    "        test_data_index = list(test_data_index)\n",
    "        train_data_index = list(train_data_index)\n",
    "        val_data_index = list(val_data_index)\n",
    "    \n",
    "    # # 获取训练样本的标签图\n",
    "    train_samples_gt = np.zeros(gt_reshape.shape)\n",
    "    for i in range(len(train_data_index)):\n",
    "        train_samples_gt[train_data_index[i]] = gt_reshape[train_data_index[i]]\n",
    "        pass\n",
    "\n",
    "    train_gt_map = train_samples_gt\n",
    "    return train_data_index,test_data_index,val_data_index, train_gt_map\n",
    "\n",
    "## function: SAM and SLIC\n",
    "def get_SAM_Segs(Img, SAM_points_in_row_width, SAM_iou_thresh, SAM_score_thresh):\n",
    "        # SAM Parameters\n",
    "    points_in_row_width = SAM_points_in_row_width\n",
    "    iou_thresh = SAM_iou_thresh\n",
    "    score_thresh = SAM_score_thresh\n",
    "\n",
    "    from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "    sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b_01ec64.pth\")\n",
    "    sam = sam.to(device)\n",
    "    mask_generator = SamAutomaticMaskGenerator(\n",
    "                    model=sam,\n",
    "                    points_per_side = points_in_row_width,\n",
    "                    # points_per_batch=64,\n",
    "                    pred_iou_thresh = iou_thresh,\n",
    "                    stability_score_thresh = score_thresh,\n",
    "                    crop_n_layers=1,\n",
    "                    crop_n_points_downscale_factor=2,\n",
    "                        min_mask_region_area=10,  # Requires open-cv to run post-processing\n",
    "                )\n",
    "\n",
    "    masks = mask_generator.generate(Img)\n",
    "    h,w = Img.shape[0],Img.shape[1]\n",
    "    z = len(masks)\n",
    "    \n",
    "    # H_SAM = coo_matrix((h*w,z),dtype=np.int8).toarray() \n",
    "    H_SAM = coo_matrix((h*w, z+1),dtype=np.int8).toarray() \n",
    "    # w_score = coo_matrix((z,1),dtype=np.int8).toarray() \n",
    "    # w_iou = coo_matrix((z,1),dtype=np.int8).toarray() \n",
    "\n",
    "    # H_SAM = np.zeros((h*w, z))\n",
    "    # w_score = np.zeros(z)\n",
    "    # w_iou = np.zeros(z)\n",
    "  \n",
    "    # stability_score\n",
    "    # predicted_iou\n",
    "\n",
    "    id_col = 0\n",
    "    for mask in masks:\n",
    "        seg = mask['segmentation']\n",
    "        seg = np.reshape(seg, -1)\n",
    "        idx = np.where(seg == True)\n",
    "\n",
    "        H_SAM[idx, id_col] =1\n",
    "        # w_score[id_col] = mask['stability_score']\n",
    "        # w_iou[id_col] = mask['predicted_iou']\n",
    "\n",
    "        id_col = id_col +1\n",
    "    \n",
    "    pos_zeros = np.where(np.all(H_SAM == 0, axis = 1))\n",
    "    pos_zeros = pos_zeros[0]\n",
    "    H_SAM[pos_zeros, z] = 1\n",
    "    \n",
    "    return H_SAM\n",
    "\n",
    "def get_SLIC_Segs(Img, SLIC_scale):\n",
    "    # SLIC Parameters\n",
    "    ###### SLIC  #########\n",
    "    h,w = Img.shape[0],Img.shape[1]\n",
    "    n_SLIC_segs = h*w/SLIC_scale\n",
    "    SLIC_segs = slic(Img, n_SLIC_segs)\n",
    "    # plt.imshow(SLIC_segs)\n",
    "    # plt.show()\n",
    "    SLIC_segs = np.reshape(SLIC_segs,(-1))\n",
    "    id_Segs = np.unique(SLIC_segs)\n",
    "    n_Segs = len(id_Segs)\n",
    "    H_SLIC = coo_matrix((h*w,n_Segs),dtype=np.int8).toarray()\n",
    "    for j in range(len(id_Segs)):\n",
    "        idx = np.where(SLIC_segs == id_Segs[j])\n",
    "        H_SLIC[idx, j] = 1\n",
    "\n",
    "    # output matlab data\n",
    "    # sio.savemat(mat_file_SLIC, {'H': H})\n",
    "    \n",
    "    return H_SLIC\n",
    "\n",
    "##################\n",
    "# Function: CreateAs\n",
    "# Date: 2023-10-29\n",
    "# Params:\n",
    "    # H: asssociated matrix\n",
    "    # S: featrue matrix\n",
    "    # sigma:kernel width\n",
    "    # vmargin: edge margin\n",
    "def CreateAs(H,S,sigma, ed_margin):  \n",
    "    # generate mask for edge set\n",
    "    HTH = H.T @ H\n",
    "    #  print(np.min(HTH))\n",
    "    #  print(np.count_nonzero(HTH == 0))    \n",
    "    M = np.zeros_like(HTH)\n",
    "    P = np.where(HTH > ed_margin)\n",
    "    M[P] = 1\n",
    "    # plt.imshow(M)\n",
    "    # plt.figure()\n",
    "\n",
    "    # edge weights: Gaussian kernel, row of S is vertex\n",
    "    R = np.linalg.norm(S, axis=1)**2\n",
    "    R = R.reshape(-1,1)\n",
    "    SST = S @ S.T\n",
    "    e = np.ones((S.shape[0], 1))\n",
    "    R = R @ e.T\n",
    "    K = R+R.T-2*SST\n",
    "    A = np.exp(-K/sigma)\n",
    "    # plt.imshow(A)\n",
    "    # plt.figure()\n",
    "\n",
    "    A = np.multiply(A, M)\n",
    "    # plt.imshow(A)\n",
    "    # plt.figure()\n",
    "    np.fill_diagonal(A, 0)  # remove diagnal \n",
    "    # plt.imshow(A)\n",
    "    # plt.figure()\n",
    "\n",
    "    return A\n",
    "\n",
    "# Function: CreateAf\n",
    "# Date: 2023-10-29\n",
    "# Params:\n",
    "    # H: asssociated matrix\n",
    "    # S: featrue matrix\n",
    "    # sigma:kernel width\n",
    "    # max_K: K neigbors\n",
    "def CreateAf(H,S,sigma, max_K):  \n",
    "    # edge weights\n",
    "    R = np.linalg.norm(S, axis=1)**2\n",
    "    R = R.reshape(-1,1)\n",
    "    SST = S @ S.T\n",
    "    e = np.ones((S.shape[0], 1))\n",
    "    R = R @ e.T\n",
    "    K = R+R.T-2*SST\n",
    "    A1 = np.exp(-K/sigma)\n",
    "    np.fill_diagonal(A1, 0)\n",
    "    A = np.zeros_like(A1) \n",
    "    for i in range(A1.shape[1]):\n",
    "        sorted_index = np.argsort(A1[:, i])[::-1]\n",
    "        A[sorted_index[:max_K],i] = A1[sorted_index[:max_K],i]\n",
    "    return 0.5*(A+A.T)    \n",
    "    \n",
    "class CTrainValTest_Sets():\n",
    "    train_data_index    = []\n",
    "    test_data_index     = []\n",
    "    val_data_index      = []\n",
    "    train_gt_map        = []\n",
    "    \n",
    "    train_gt            = []\n",
    "    val_gt              = []\n",
    "    test_gt             = []\n",
    "\n",
    "    def get_TrainValTest_Sets(self, cur_seed,\n",
    "            gt,class_num,train_ratio,val_ratio, samples_type):\n",
    "        (train_data_index,\n",
    "         test_data_index, \n",
    "         val_data_index, \n",
    "         train_gt_map) = get_TrainValTest_Sets(cur_seed,\n",
    "                gt,class_num, train_ratio,val_ratio, samples_type)\n",
    "         \n",
    "        gt_flatten = np.reshape(gt, -1)\n",
    "        \n",
    "        # label of training set\n",
    "        train_gt = gt_flatten[train_data_index]\n",
    "        train_gt = train_gt - 1\n",
    "        train_gt = torch.from_numpy(train_gt).to(device)\n",
    "        self.train_gt = train_gt.long()\n",
    "    \n",
    "        # label of valid set\n",
    "        val_gt = gt_flatten[val_data_index]\n",
    "        val_gt = val_gt - 1\n",
    "        val_gt = torch.from_numpy(val_gt).to(device)\n",
    "        self.val_gt = val_gt.long()\n",
    "        \n",
    "        # label of test set\n",
    "        test_gt = gt_flatten[test_data_index]\n",
    "        test_gt = test_gt - 1\n",
    "        test_gt = torch.from_numpy(test_gt).to(device)\n",
    "        self.test_gt = test_gt.long()\n",
    "        \n",
    "        self.train_data_index   = train_data_index\n",
    "        self.test_data_index    =  test_data_index\n",
    "        self.val_data_index     =  val_data_index\n",
    "        self.train_gt_map       =  train_gt_map\n",
    "        \n",
    "        pass\n",
    "\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc\n",
    "def get_HSI_performance(ytruth, ypredict):\n",
    "    oa = accuracy_score(ytruth, ypredict)\n",
    "    confusion = confusion_matrix(ytruth, ypredict)\n",
    "    acc_perclass, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(ytruth, ypredict)\n",
    "    return oa, aa, kappa, acc_perclass, confusion\n",
    "class CLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLoss, self).__init__()\n",
    "        self.cost = nn.CrossEntropyLoss()\n",
    "    def forward(self, X, Y):\n",
    "        loss = self.cost(X, Y)\n",
    "        return loss\n",
    "    \n",
    "def getHSI_dataset(FLAG):\n",
    "    if FLAG == 1:\n",
    "        data_mat = sio.loadmat('HyperImage_data\\indian\\Indian_pines_corrected.mat')\n",
    "        data = data_mat['indian_pines_corrected']\n",
    "        gt_mat = sio.loadmat('HyperImage_data\\indian\\Indian_pines_gt.mat')\n",
    "        gt = gt_mat['indian_pines_gt']\n",
    "        # 参数预设\n",
    "        # train_ratio = 0.05  # 训练集比例。注意，训练集为按照‘每类’随机选取\n",
    "        val_ratio = 0.01  # 测试集比例.注意，验证集选取为从测试集整体随机选取，非按照每类\n",
    "        class_num = 16  # 样本类别数\n",
    "        learning_rate = 5e-4  # 学习率: 5e-4\n",
    "        max_epoch =600  # 迭代次数\n",
    "        dataset_name = \"indian_\"  # 数据集名称\n",
    "        pass\n",
    "    return data, gt, val_ratio, class_num, learning_rate, max_epoch, dataset_name \n",
    "class CResult():\n",
    "\n",
    "    lossvalue = 0\n",
    "    def get_permance(self, gt, output):\n",
    "        gt = gt.cpu()\n",
    "        pre = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "        \n",
    "        (oa, aa, kappa, \n",
    "            acc_perclass, confusion) = \\\n",
    "                get_HSI_performance(gt, pre)\n",
    "        self.oa = oa\n",
    "        self.aa = aa\n",
    "        self.kappa = kappa\n",
    "        self.acc_perclass = acc_perclass\n",
    "        self.confusion = confusion     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:0.39429500699043274 \toa_test:0.9268122444909762\n",
      "test_loss:0.42143920063972473 \toa_test:0.9244191843653405\n",
      "test_loss:0.4278818368911743 \toa_test:0.9073686309701865\n",
      "test_loss:0.24124205112457275 \toa_test:0.9455578821417888\n",
      "test_loss:0.23888355493545532 \toa_test:0.9549307009671951\n",
      "test_loss:0.37576955556869507 \toa_test:0.9318974972579519\n",
      "test_loss:0.335236519575119 \toa_test:0.9374813042177684\n",
      "test_loss:0.5670275688171387 \toa_test:0.8948050653105992\n",
      "test_loss:0.733957052230835 \toa_test:0.8983946554990527\n",
      "test_loss:0.4077586233615875 \toa_test:0.9092631369029813\n",
      "\n",
      "train_ratio=0.01 \n",
      "==============================================\n",
      "OA= 0.923093030212384 +- 0.019149883843099545\n",
      "AA= 0.9386599127913392 +- 0.01718013157608865\n",
      "Kpp= 0.9122829586902977 +- 0.021820700352301475\n",
      "AVG= [0.98863636 0.86502146 0.87783251 0.90735931 0.85750529 0.99803922\n",
      " 1.         1.         1.         0.85714286 0.96029106 0.78812392\n",
      " 0.99748744 0.99096045 0.93015873 1.        ] +- [0.01136364 0.07321483 0.1330218  0.11135222 0.11167995 0.00218775\n",
      " 0.         0.         0.         0.06147067 0.03446795 0.19295303\n",
      " 0.00251256 0.00769757 0.10611203 0.        ]\n",
      "Average training time:5.247254109382629\n",
      "Average testing time:0.0035094738006591795\n"
     ]
    }
   ],
   "source": [
    "############ MAIN PROG ############################\n",
    "class structConstParams:\n",
    "    FLAG = 1   # 1:indian, 2: salinas, 3:paviaU, 4: KSC ,5:HSD\n",
    "    max_iters = 400\n",
    "    samples_type = 'ratio' # 'ratio', 'same_num'\n",
    "    train_ratio = 0.01 # salinas:, paviaU:0.001\n",
    "    SLIC_scale = 100            \n",
    "    H_SAM_and_H_SLIC = 0    # 0: SAM, 1: SLIC, 2: SAM+SLIC         \n",
    "    # parameters of graph As and Af \n",
    "    sigma_AS = 1\n",
    "    ed_margin_AS = 0.0 \n",
    "    sigma_Af = 1\n",
    "    max_K_af = 3\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "CP = structConstParams()\n",
    "Seed_List=[4242,4243,4244,4255,4266,4277,4288,4299,4311,4411]#随机种子点\n",
    "# Seed_List=[4255] #随机种子点\n",
    "\n",
    "## 1) prepare data \n",
    "#  get HSI data from matlab dataset\n",
    "(data, gt, val_ratio, class_num, learning_rate, \n",
    "        max_epoch, dataset_name) = getHSI_dataset(CP.FLAG)\n",
    "gt_flatten = np.reshape(gt, -1)\n",
    "ori_data = data\n",
    "(height, width, bands) = data.shape\n",
    "data = (data - float(np.min(data)))\n",
    "data = data/np.max(data)\n",
    "\n",
    "TVT_sets = CTrainValTest_Sets()\n",
    "TVT_sets.get_TrainValTest_Sets(4242,\n",
    "        gt,\n",
    "        class_num,\n",
    "        CP.train_ratio,\n",
    "        val_ratio, \n",
    "        CP.samples_type)\n",
    "data_flatten = np.reshape(data,[-1,data.shape[2]])\n",
    "data_train = data_flatten[TVT_sets.train_data_index]\n",
    "y_train = gt_flatten[TVT_sets.train_data_index]\n",
    "\n",
    "del TVT_sets,data_flatten,data_train,y_train\n",
    "### fun: obtain_H_from_HSI ##\n",
    "# Obtain H from image\n",
    "# SAM paramters: \n",
    "# FLAG: 1:indian, 2: salinas, 3:paviaU, 4: KSC\n",
    "def obtain_H_from_HSI(FLAG, H_SAM_and_H_SLIC, SLIC_scale):\n",
    "    if FLAG == 1:\n",
    "        SAM_points_in_row_width = 32     # grid in per row and col: 64\n",
    "        SAM_score_thresh = 0.4     # score threshold: 0.8\n",
    "        SAM_iou_thresh = 0.4     # iou   threshold: 0.1\n",
    "        X_3Band = data[:,:,[43,21,11]] \n",
    "    # 将标准化数据映射到0-255的范围内\n",
    "    X_3Band = np.reshape(X_3Band,(data.shape[0],data.shape[1],3))\n",
    "    min_value = np.min(X_3Band)\n",
    "    max_value = np.max(X_3Band)\n",
    "    X_3Band = (X_3Band - min_value) * 255 / (max_value - min_value)\n",
    "    # 将数据转换为整型\n",
    "    X_3Band = X_3Band.astype(np.uint8)\n",
    "    H_SAM = get_SAM_Segs(X_3Band, SAM_points_in_row_width, SAM_iou_thresh, SAM_score_thresh)\n",
    "    H_SLIC = get_SLIC_Segs(X_3Band, SLIC_scale)\n",
    "    if H_SAM_and_H_SLIC==0:\n",
    "        H = H_SAM\n",
    "    if H_SAM_and_H_SLIC==1:\n",
    "        H = H_SLIC\n",
    "    if H_SAM_and_H_SLIC==2:\n",
    "        H =np.hstack((H_SAM, H_SLIC))\n",
    "    return H\n",
    "###############\n",
    "    \n",
    "H = obtain_H_from_HSI(CP.FLAG, CP.H_SAM_and_H_SLIC, CP.SLIC_scale)\n",
    "H = H.astype(float)\n",
    "dv = np.sum(H, axis = 0)\n",
    "Dv_inv = np.diag(1/dv)\n",
    "HD = H @ Dv_inv\n",
    "data_Flatten = np.reshape(data, (-1, data.shape[2]))\n",
    "data_Flatten = data_Flatten.astype(np.float32)\n",
    "S = HD.T @ data_Flatten\n",
    "\n",
    "#================================================\n",
    "#get the pixels that do not blong to superpixels\n",
    "HI = H.astype(bool)\n",
    "Pos0 = np.where(np.all(HI==0, axis=1))\n",
    "Pos0 = Pos0[0]\n",
    "\n",
    "t = 0\n",
    "#=================================================\n",
    "\n",
    "# generate As\n",
    "As = CreateAs(H,S, CP.sigma_AS, CP.ed_margin_AS)\n",
    "# generate Af\n",
    "Af = CreateAf(H,S, CP.sigma_Af, CP.max_K_af)\n",
    "\n",
    "data_torch = torch.tensor(data, dtype=torch.float).to(device)\n",
    "S_torch = torch.tensor(S,dtype=torch.float).to(device) # supprpixel\n",
    "H_torch = torch.tensor(H, dtype=torch.float).to(device) # H: transform between pixel and superpixel\n",
    "As_torch = torch.tensor(As, dtype=torch.float).to(device)\n",
    "Af_torch = torch.tensor(Af, dtype=torch.float).to(device)\n",
    "Pos0_torch = torch.tensor(Pos0, dtype=torch.int).to(device)\n",
    "\n",
    "K = 3\n",
    "CP.AIGCN_K_As = K\n",
    "CP.AIGCN_K_Af  = K\n",
    "CP.AIGCN_K_Ac  = K\n",
    "## 2) \n",
    "OA_ALL = []\n",
    "AA_ALL = []\n",
    "KPP_ALL = []\n",
    "AVG_ALL = []\n",
    "Train_Time_ALL=[]\n",
    "Test_Time_ALL=[]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for cur_seed in Seed_List:\n",
    "    # random.seed(cur_seed)\n",
    "    \n",
    "    ###### train, valid, and test sets ####\n",
    "    TVT_sets = CTrainValTest_Sets()\n",
    "    TVT_sets.get_TrainValTest_Sets(cur_seed,\n",
    "            gt,\n",
    "            class_num,\n",
    "            CP.train_ratio,\n",
    "            val_ratio, \n",
    "            CP.samples_type)\n",
    "    \n",
    "    resut_train = CResult()\n",
    "    resut_val = CResult()\n",
    "    resut_test = CResult()\n",
    "    #############################\n",
    "    \n",
    "    ####### network object ##########\n",
    "    net = AIGCN_NET(height, width, bands, class_num, \n",
    "                H_torch, Pos0_torch, As_torch, Af_torch, CP.AIGCN_K_As, CP.AIGCN_K_Af, CP.AIGCN_K_Ac)\n",
    "    net.to(device)\n",
    "    \n",
    "    # loss object\n",
    "    cal_loss = CLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(),\n",
    "            lr = learning_rate) #,weight_decay=0.0001\n",
    "    net.train()\n",
    "    \n",
    "    best_loss = 99999\n",
    "    tic_train = time.time()\n",
    "    for i in range(CP.max_iters+1):\n",
    "        # network forward\n",
    "        optimizer.zero_grad()\n",
    "        output= net(data_torch)\n",
    "        \n",
    "        output_train = output[TVT_sets.train_data_index]\n",
    "        loss = cal_loss(output_train, TVT_sets.train_gt)\n",
    "        \n",
    "        loss.backward(retain_graph=False)\n",
    "        optimizer.step()  # Does the update\n",
    "\n",
    "        if i%10 == 0:\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                output = net(data_torch)\n",
    "                \n",
    "                output_train = output[TVT_sets.train_data_index]\n",
    "                loss_train = cal_loss(output_train, TVT_sets.train_gt)\n",
    "                resut_train.get_permance(TVT_sets.train_gt, output_train)\n",
    "                resut_train.lossvalue = loss_train.item()\n",
    "            \n",
    "                output_val = output[TVT_sets.val_data_index]\n",
    "                loss_val = cal_loss(output_val, TVT_sets.val_gt)\n",
    "                resut_val.get_permance(TVT_sets.val_gt, output_val)\n",
    "                resut_val.lossvalue = loss_val.item()\n",
    "     \n",
    "                # print(\"{}\\t train_loss: {} \\tval_loss:{} \\toa_train:{} \\toa_val:{}\".format(str(i+1), \n",
    "                #                     loss_train, loss_val, resut_train.oa, resut_val.oa))\n",
    "        \n",
    "                if  loss_val < best_loss:\n",
    "                    best_loss = loss_val\n",
    "                    torch.save(net.state_dict(),\"model\\\\AIGCNs.pt\")\n",
    "            torch.cuda.empty_cache()\n",
    "            net.train()\n",
    "            toc1 = time.time()\n",
    "    \n",
    "    toc_train = time.time()\n",
    "    Train_Time_ALL.append(toc_train-tic_train)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        net.load_state_dict(torch.load(\"model\\\\AIGCNs.pt\"))\n",
    "        net.eval()\n",
    "        tic_test = time.time()\n",
    "        output = net(data_torch)\n",
    "        toc_test = time.time()\n",
    "        Test_Time_ALL.append(toc_test-tic_test)\n",
    "        \n",
    "        # performance for classification\n",
    "        output_test = output[TVT_sets.test_data_index]\n",
    "        loss_val = cal_loss(output_test, TVT_sets.test_gt)\n",
    "        resut_test.get_permance(TVT_sets.test_gt, output_test)\n",
    "        print(\"test_loss:{} \\toa_test:{}\".format(loss_val, resut_test.oa))\n",
    "        \n",
    "        # testOA, testAA, testkappa\n",
    "        AVG_ALL.append(resut_test.acc_perclass)\n",
    "        OA_ALL.append(resut_test.oa)\n",
    "        AA_ALL.append(resut_test.aa)\n",
    "        KPP_ALL.append(resut_test.kappa)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    del net\n",
    "OA_ALL = np.array(OA_ALL)\n",
    "AA_ALL = np.array(AA_ALL)\n",
    "KPP_ALL = np.array(KPP_ALL)\n",
    "AVG_ALL = np.array(AVG_ALL)\n",
    "Train_Time_ALL=np.array(Train_Time_ALL)\n",
    "Test_Time_ALL=np.array(Test_Time_ALL)\n",
    "\n",
    "\n",
    "print(\"\\ntrain_ratio={}\".format(CP.train_ratio),\n",
    "        \"\\n==============================================\")\n",
    "print('OA=', np.mean(OA_ALL), '+-', np.std(OA_ALL))\n",
    "print('AA=', np.mean(AA_ALL), '+-', np.std(AA_ALL))\n",
    "print('Kpp=', np.mean(KPP_ALL), '+-', np.std(KPP_ALL))\n",
    "print('AVG=', np.mean(AVG_ALL, 0), '+-', np.std(AVG_ALL, 0))\n",
    "print(\"Average training time:{}\".format(np.mean(Train_Time_ALL)))\n",
    "print(\"Average testing time:{}\".format(np.mean(Test_Time_ALL)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\python38\\lib\\site-packages\\spectral\\graphics\\spypylab.py:796: UserWarning: Failed to create RectangleSelector object. Interactive pixel class labeling will be unavailable.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 145x145 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Draw_Classification_Map(label, name: str, scale: float = 4.0, dpi: int = 400):  # 绘制全分类图\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    numlabel = np.array(label)\n",
    "    v = spectral.imshow(classes=numlabel.astype(np.int16), fignum=fig.number)\n",
    "    ax.set_axis_off()\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    fig.set_size_inches(label.shape[1] * scale /\n",
    "                        dpi, label.shape[0] * scale / dpi)\n",
    "    foo_fig = plt.gcf()  # 'get current figure'\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    foo_fig.savefig(name + '.png', format='png',\n",
    "                    transparent=True, dpi=dpi, pad_inches=0)\n",
    "output = output.cpu().detach().numpy()  \n",
    "output = np.argmax(output,axis=1) \n",
    "output = output+1\n",
    "output = np.reshape(output,(gt.shape[0],gt.shape[1]))  \n",
    "ids = np.where(gt == 0)\n",
    "output[ids] = 0            \n",
    "Draw_Classification_Map(output,'map') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
